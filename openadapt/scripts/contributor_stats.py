"""Print stats about contributors"""

from collections import defaultdict
from datetime import datetime
import dateutil
import glob
import os
import requests
import shutil
import time

from fpdf import FPDF
from git import Repo
from github import Github
from loguru import logger
from tqdm import tqdm
import fire
import unidiff

import openadapt as oa


AUTOGENERATED_FILES = [
    "frontend/package-lock.json",
    "frontend/package.json",
    "frontend/jsconfig.json",
    "frontend/babel.config.js",
    "frontend/README.md",
    "frontend/.gitignore",
    "frontend/.browserslistrc",
    "frontend/public/index.html",
    "frontend/src/App.vue",
    "frontend/src/components/Carousel.vue",
    "frontend/src/main.js",
    "frontend/src/plugins/vuetify.js",
    "frontend/src/plugins/webfontloader.js",
    "frontend/src/router/index.js",
    "frontend/src/store/index.js",
    "frontend/src/views/HomeView.vue",
    "frontend/vue.config.js",
    ".idea/.gitignore",
    ".idea/PAT.iml",
    ".idea/inspectionProfiles/Project_Default.xml",
    ".idea/inspectionProfiles/profiles_settings.xml",
    ".idea/misc.xml",
    ".idea/modules.xml",
    ".idea/vcs.xml",
    "marketplace-frontend/.browserslistrc",
    "marketplace-frontend/.gitignore",
    "marketplace-frontend/README.md",
    "marketplace-frontend/babel.config.js",
    "marketplace-frontend/jsconfig.json",
    "marketplace-frontend/package-lock.json",
    "marketplace-frontend/package.json",
    "marketplace-frontend/public/favicon.ico",
    "marketplace-frontend/public/index.html",
    "marketplace-frontend/src/App.vue",
    "marketplace-frontend/src/components/Carousel.vue",
    "marketplace-frontend/src/components/SearchBar.vue",
    "marketplace-frontend/src/main.js",
    "marketplace-frontend/src/plugins/vuetify.js",
    "marketplace-frontend/src/plugins/webfontloader.js",
    "marketplace-frontend/src/router/index.js",
    "marketplace-frontend/vue.config.js",
]
DUPLICATE_FILES = [
    "puterbot/strategies/minigpt4.py",
]
COPIED_FILES = [
    "openadapt/minigpt4_demo_modal.py",
    "openadapt/strategies/minigpt4.py",
]
TEXT_FILES = [
    "README.md",
    "CONTRIBUTING.md",
]
IGNORED_FILES = AUTOGENERATED_FILES + DUPLICATE_FILES + COPIED_FILES + TEXT_FILES


def pr_stats(ignored_files=IGNORED_FILES, end_date_str=None):
    end_date = dateutil.parser.parse(str(end_date_str)).date() if end_date_str else None
    logger.info(f"{end_date=}")

    g = Github(oa.config.GITHUB_ACCESS_TOKEN)

    user_pr_lines_of_code = defaultdict(lambda: defaultdict(int))
    user_pr_urls = defaultdict(dict)
    user_pr_diffs = defaultdict(lambda: defaultdict(str))

    for repo_path in oa.config.GITHUB_REPO_PATHS:
        logger.info(f"\nProcessing repo: {repo_path}")
        repo = g.get_repo(repo_path)
        prs = repo.get_pulls(state="all")

        for pr in tqdm(prs, desc="Processing PRs"):
            pr_date = pr.created_at.date()
            if end_date and pr_date > end_date:
                logger.info(f"skipping {pr_date=} {pr.user.login=}")
                continue

            if pr.state == "closed" and not pr.merged:
                continue

            user = pr.user.login

            diff_url = pr.diff_url
            headers = {
                "Authorization": f"token {oa.config.GITHUB_ACCESS_TOKEN}",
                "Accept": "application/vnd.github.v3.diff",
            }
            diff_response = requests.get(diff_url, headers=headers)
            parsed_diff = unidiff.PatchSet(diff_response.text)

            for file in parsed_diff:
                if file.path not in ignored_files:
                    for hunk in file:
                        for line in hunk:
                            if line.is_added or line.is_removed:
                                user_pr_lines_of_code[user][pr.number] += 1
                                user_pr_diffs[user][pr.number] += str(line) + "\n"

            user_pr_urls[user][pr.number] = pr.html_url

    # Sort the user_lines_of_code dictionary by value in descending order
    user_pr_lines_of_code_sorted = dict(
        sorted(
            user_pr_lines_of_code.items(),
            key=lambda item: sum(item[1].values()),
            reverse=True,
        )
    )

    # Display the lines of code and PR URLs per user
    for user, pr_lines_of_code in user_pr_lines_of_code_sorted.items():
        total_lines_of_code = sum(pr_lines_of_code.values())
        logger.info(f"\nUser: {user}, Total Lines of code: {total_lines_of_code}")

        # Sort PRs by line count in descending order
        sorted_prs = sorted(
            pr_lines_of_code.items(), key=lambda item: item[1], reverse=True
        )

        for pr_number, lines_of_code in sorted_prs:
            pr_url = user_pr_urls[user][pr_number]
            logger.info(
                f"PR Number: {pr_number}, "
                f"Lines of code: {lines_of_code}, PR URL: {pr_url}"
            )
    return user_pr_lines_of_code_sorted, user_pr_urls, user_pr_diffs


def repo_stats(ignored_files=IGNORED_FILES, end_date_str=None):
    end_date = dateutil.parser.parse(str(end_date_str)).date() if end_date_str else None
    logger.info(f"{end_date=}")

    g = Github(oa.config.GITHUB_ACCESS_TOKEN)

    user_lines_of_code = defaultdict(int)

    for repo_path in oa.config.GITHUB_REPO_PATHS:
        logger.info(f"{repo_path=}")
        repo = g.get_repo(repo_path)

        # Clone the repo
        repo_clone_path = "/tmp/" + repo.name
        if os.path.exists(repo_clone_path):
            shutil.rmtree(repo_clone_path)
        cloned_repo = Repo.clone_from(repo.clone_url, repo_clone_path)

        prs = repo.get_pulls(state="all")

        for pr in prs:
            pr_date = pr.created_at.date()
            if end_date and pr_date > end_date:
                logger.info(f"skipping {pr_date=} {pr.user.login=}")
                continue

            user = pr.user.login
            branch = pr.head.ref

            # Check if the PR is from a fork, if so use its clone URL
            if pr.head.repo != repo:
                remote_url = pr.head.repo.clone_url
            else:
                remote_url = repo.clone_url

            # Add and fetch the remote
            remote_name = "remote_" + str(pr.number)
            try:
                remote = cloned_repo.create_remote(remote_name, url=remote_url)
                remote.fetch()
                logger.info(f"Successfully fetched from remote: {remote_name}")
            except Exception as e:
                logger.info(f"Failed to fetch from remote: {remote_name}. Error: {e}")
                continue

            # Checkout to the PR branch
            full_branch_name = remote_name + "/" + branch
            try:
                cloned_repo.git.checkout(full_branch_name, f=True)
                logger.info(f"Successfully checked out branch: {full_branch_name}")
            except Exception as e:
                if "local changes" in str(e):
                    import ipdb

                    ipdb.set_trace()
                logger.info(
                    f"Failed to checkout branch: {full_branch_name}. Error: {e}"
                )
                continue

            # Count the lines of code in the branch
            try:
                for commit in cloned_repo.iter_commits(full_branch_name):
                    stats = commit.stats
                    total_lines = 0
                    for filename in stats.files:
                        if any(
                            glob.fnmatch.fnmatch(filename, pattern)
                            for pattern in ignored_files
                        ):
                            logger.info(f"ignoring {filename=}")
                            continue
                        total_lines += stats.files[filename]["lines"]
                    user_lines_of_code[user] += total_lines
                logger.info(f"Successfully counted lines of code for user: {user}")
            except Exception as e:
                logger.info(f"Error counting for user: {user}. Error: {e}")

    # Sort the user_lines_of_code dictionary by value in descending order
    user_lines_of_code_sorted = dict(
        sorted(user_lines_of_code.items(), key=lambda item: item[1], reverse=True)
    )

    # Display the lines of code per user
    for user, lines_of_code in user_lines_of_code.items():
        logger.info(f"User: {user}, Lines of code: {lines_of_code}")

    return user_lines_of_code_sorted


def export(prs=True, repo=False, end_date_str=None):
    assert prs or repo, (prs, repo)
    if repo:
        user_lines_of_code_sorted = repo_stats(end_date_str=end_date_str)
    if prs:
        user_pr_lines_of_code_sorted, user_pr_urls, user_pr_diffs = pr_stats(
            end_date_str=end_date_str
        )

    end_date = (
        dateutil.parser.parse(str(end_date_str)).date()
        if end_date_str
        else datetime.now().date()
    )
    logger.info(f"{end_date=}")

    # Start the HTML document
    html = f"""
    <html>
    <head>
        <title>Contribution Stats for {end_date_str}</title>
    </head>
    <body>
        <h1>Contribution Stats for {end_date_str}</h1>
    """

    if repo:
        html += """
        <h2>User Lines of Code</h2>
        <ul>
        """
        # Add the user lines of code sorted
        for user, lines_of_code in user_lines_of_code_sorted.items():
            html += f"<li>User: {user}, Total Lines of code: {lines_of_code}</li>"

        html += "</ul>"

    if prs:
        # Add the user PR lines of code sorted
        html += "<h2>User PR Lines of Code and Diffs</h2>"
        for user, pr_lines_of_code in user_pr_lines_of_code_sorted.items():
            total_lines_of_code = sum(pr_lines_of_code.values())
            html += (
                f"<h3>User: {user}, PR Lines of code: {total_lines_of_code}</h3><ul>"
            )

            # Sort PRs by line count in descending order
            sorted_prs = sorted(
                pr_lines_of_code.items(), key=lambda item: item[1], reverse=True
            )

            for pr_number, lines_of_code in sorted_prs:
                pr_url = user_pr_urls[user][pr_number]
                pr_diff = user_pr_diffs[user][pr_number].replace(
                    "\n", "<br/>"
                )  # convert newlines to HTML breaks

                html += f"<li>PR Number: {pr_number}, Lines of code: {lines_of_code}, PR URL: <a href='{pr_url}'>{pr_url}</a></li>"

                # Add collapsible diffs
                html += f"""
                <details>
                    <summary>View diff</summary>
                    <pre>{pr_diff}</pre>
                </details>
                """

            html += "</ul>"

    html += f"<h2>AUTOGENERATED_FILES</h2><ul>"
    for file in AUTOGENERATED_FILES:
        html += f"<li>{file}</li>"
    html += "</ul>"

    html += f"<h2>DUPLICATE_FILES</h2><ul>"
    for file in DUPLICATE_FILES:
        html += f"<li>{file}</li>"
    html += "</ul>"

    html += f"<h2>COPIED_FILES</h2><ul>"
    for file in COPIED_FILES:
        html += f"<li>{file}</li>"
    html += "</ul>"

    html += f"<h2>TEXT_FILES</h2><ul>"
    for file in TEXT_FILES:
        html += f"<li>{file}</li>"
    html += "</ul>"

    html += "</body></html>"

    # Write the HTML to a file
    fname = f"contribution_stats-{end_date.strftime(oa.config.DATE_FMT)}.html"
    with open(fname, "w") as file:
        file.write(html)

    print(f"Saved contribution stats as {fname=}")


if __name__ == "__main__":
    fire.Fire(oa.utils.get_functions(__name__))
